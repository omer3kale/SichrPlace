# MJS Code Quality Operations Plan

## Overview
- Total `.mjs` files (excl. `node_modules`): 238 (`.netlify`: 119, `netlify`: 111, `organized`: 4, `scripts`: 4)
- Current Jest suites do **not** execute any `.mjs` modules; all Netlify handlers and automation scripts ship without automated coverage.
- Objective: establish testing, linting, and lifecycle controls for all ESM serverless code while pruning generated artifacts.

## Cross-Cutting Tasks
- [ ] Extend root Jest setup (or create `jest.netlify.config.cjs`) with ESM support using `@swc/jest` or `babel-jest` and `extensionsToTreatAsEsm` for `.mjs`.
- [ ] Configure `eslint` with `plugin:import` ESM rules and apply to `netlify/**/*.mjs`, `scripts/*.mjs`, `organized/js/*.mjs`.
- [ ] Add `npm run lint:esm` and `npm run test:netlify` scripts; wire into CI.
- [ ] Provide common test helpers for environment variables, Supabase mocks, Slack/UptimeRobot stubs.
- [ ] Update documentation (`ENVIRONMENT_SETUP_GUIDE.md`) with env vars required for test harnesses (Slack webhook, UptimeRobot, Supabase keys).

## Directory Audit & Required Operations

### `.netlify/` (119 files)
- Generated by Netlify CLI (`functions-serve`, telemetry shims).
- [ ] Confirm `.netlify/` is ignored by git; remove currently tracked assets.
- [ ] Exclude directory from lint/test tooling to avoid duplicating handlers.
- [ ] Automate cleanup before running coverage (`rimraf .netlify/functions-serve`).

### `netlify/functions/` (111 runtime files)
- Production Lambda handlers.
- [ ] Create `netlify/functions/__tests__/` with unit tests per critical domain (auth, feedback, monitoring, payments, analytics).
- [ ] Implement smoke test iterating every handler to ensure `export async function handler(event, context)` exists.
- [ ] Mock external dependencies:
  - Supabase client via `@supabase/supabase-js` jest mock.
  - Slack webhook (capture payloads and assert severity mapping).
  - UptimeRobot REST calls using `nock`.
- [ ] Add schema validation tests for feedback payload (`feedback.mjs`) and monitoring dashboard responses.
- [ ] Track minimum coverage thresholds (target ≥80% statements) once baseline tests land.

### `organized/js/*.mjs` (4 orchestration scripts)
- Smoke-test orchestrators for production readiness.
- [ ] Audit usage; if still required, add integration harness that runs each script in dry-run mode.
- [ ] Document invocation in `docs/QA_PLAYBOOK.md`; otherwise archive obsolete utilities.

### `scripts/*.mjs` (4 automation scripts)
- Deployment, security validation, and Supabase tooling.
- [ ] Add CLI argument parsing tests where pure logic exists.
- [ ] Provide Windows-compatible entrypoints (current scripts assume Node/binary availability).
- [ ] Ensure secrets handling (e.g., `secret-scan.mjs`) redacts output; add regression tests.

## Documentation Updates
- [ ] Reference this plan from `docs/CRITICAL_FOLLOWUP_STATUS.md` and link to execution progress.
- [ ] Add checklist entry in `PROJECT_STATUS_TRACKER.md` for “Netlify function tests (ESM)”.
- [ ] Include test commands (`npm run test:netlify`, `npm run lint:esm`) in `docs/CI_CD_COMPLETE.md` once implemented.

## Execution Roadmap
1. Clean generated `.netlify` artifacts and enforce git ignore rules.
2. Establish Jest/ESLint infrastructure supporting `.mjs` (ESM) modules.
3. Prioritize Netlify production handlers (auth, feedback, monitoring) for automated tests and coverage.
4. Backfill tests for supporting orchestration and automation scripts.
5. Update status and CI documentation when thresholds are met.

Following this sequence will bring serverless ESM code to parity with the rest of the production readiness work and enable reliable regression testing before deployment.
